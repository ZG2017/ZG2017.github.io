---
layout: default
title: Research Publications
permalink: /research/
---

# üìö Research Publications

## Recent Publications

### 1. **E-CARE: An Efficient LLM-based Commonsense-Augmented Framework for E-Commerce**
- **Authors**: **Ge Zhang**, et al.
- **Abstract**: We introduce E-CARE, a cost-efficient LLM-augmented framework that distills domain commonsense into a factor graph, enabling one LLM call per query for e-commerce relevance and retrieval. It yields up to 12.79% Macro F1 and 12.1% Recall@5 gains.
- **Status**: under review of WWW 2026.
- **Key Contributions**: 
  - Distill domain commonsense from historical query‚Äìproduct pairs into a reasoning factor graph.
  - Three-stage pipeline requiring no SFT or human annotation.
  - Consistent gains on search relevance and app recall (up to 12.79% Macro F1, 12.1% Recall@5).

### 2. [**Path-of-Thoughts: Robust Relational Reasoning with LLMs**](https://arxiv.org/abs/2412.17963)
- **Authors**: **Ge Zhang**, MA Alomrani, H Gu, J Zhou, Y Hu, B Wang, Q Liu, M Coates
- **Abstract**: Path-of-Thoughts (PoT) decomposes relational reasoning into graph extraction, path identification, and reasoning, achieving up to 21.3% improvements on long-chain benchmarks with few LLM calls and improved robustness.
- **Key Contributions**:
  - Single-call prompting to extract task-agnostic graphs and queries.
  - Path identification over graphs to infer answers via multiple chains.
  - Strong results on kinship and spatial benchmarks, including a large Chinese kinship dataset.

### 3. [**Sparse Decomposition of Graph Neural Networks**](https://arxiv.org/abs/2410.19723)
- **Authors**: Y Hu, M Zeng, **Ge Zhang**, P Rumiantsev, L Ma, Y Zhang, M Coates
- **Abstract**: We introduce a sparse decomposition framework that factorizes GNN hidden representations into a small set of basis components with sparse coefficients, improving interpretability and efficiency while retaining predictive performance.
- **Key Contributions**:
  - Formulate sparse factorization for GNN representations with an efficient optimization objective.
  - Provide analysis showing regularization and interpretability benefits without sacrificing expressivity.
  - Empirically demonstrate competitive accuracy with reduced complexity and clearer explanations across standard graph benchmarks.

### 4. [**Enhancing Logical Reasoning in Large Language Models through Graph-based Synthetic Data**](https://arxiv.org/abs/2409.12437)
- **Authors**: J Zhou, A Ghaddar, **Ge Zhang**, L Ma, Y Hu, S Pal, M Coates, B Wang
- **Abstract**: We generate graph-structured synthetic data that encodes compositional relations and reasoning chains, and use it to augment LLM training/evaluation, yielding consistent gains on multi-step logical reasoning without task-specific fine-tuning.
- **Key Contributions**:
  - Procedure to synthesize graph-grounded reasoning instances and prompts that cover diverse logical patterns.
  - Data augmentation curriculum that injects compositional structure and longer reasoning chains.
  - Improved accuracy and robustness on multi-step reasoning benchmarks versus strong baselines.

### 5. [**Optimized Design of THz Microstrip Antenna Based on Dual-Surfaced Multiple Split-Ring Resonators**](https://ieeexplore.ieee.org/document/8072920)
- **Authors**: **Ge Zhang**, S Pu, XY Xu, C Tao, JY Dun
- **Venue**: 2017 IEEE International Symposium on Antennas and Propagation & USNC/URSI, 2017

### 6. [**Design of 60-GHz Microstrip Antenna Array Composed Through Circular Contour Feeding Line**](https://ieeexplore.ieee.org/document/7522931)
- **Authors**: **Ge Zhang**, S Pu, X Xu, Y Liu, C Wang
- **Venue**: 2016 Asia-Pacific International Symposium on Electromagnetic Compatibility, 2016

### 7. [**Design of 60 GHz Microstrip Antenna Array Composed Through Annular Feeding Line**](https://ieeexplore.ieee.org/document/7696531)
- **Authors**: **Ge Zhang**, S Pu, ZR Liu, WF Liu
- **Venue**: IEEE International Symposium on Antennas and Propagation (APSURSI), 2016

## Patents Filed

### **NURG: An Efficient Learning-to-Rank Framework with Commonsense Reasoning from Large Language Models** (US Patent Application 19/337,555, 2025)
- **Authors**: **Ge Zhang**, R Ajwani, H Gu, Y Hu, Y Zhang

### **Methods and Processors for Relational Reasoning from Text** (US Patent Application 19/074,860, 2025)
- **Authors**: **Ge Zhang**, MA Alomrani, H Gu, Y Hu, Y Zhang

---

## üìß Contact Information

- **Email**: [gz19950616@gmail.com](mailto:gz19950616@gmail.com)
- **Phone**: +1-6476711919
- **Google Scholar**: [View Profile](https://scholar.google.ca/citations?user=_YDDusIAAAAJ&hl=en)
- **GitHub**: [github.com/ZG2017](https://github.com/ZG2017)

---

[‚Üê Back to Home](/)
